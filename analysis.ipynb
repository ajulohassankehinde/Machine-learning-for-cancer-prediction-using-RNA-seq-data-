{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b05c990e",
      "metadata": {
        "id": "b05c990e"
      },
      "source": [
        "# Neural Network for Cancer Prediction\n",
        "The data used for this tutorial is an RNA-seq gene expression data for different cancer types. The rows represent cancer samples and the columns represent gene count values. The last column contains the cancer categories.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d7202fe",
      "metadata": {
        "id": "5d7202fe"
      },
      "source": [
        "## Required Libraries\n",
        " - numpy\n",
        " - matplotlib\n",
        " - pandas\n",
        " - tensorflow\n",
        " - keras\n",
        " - scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91f3dde3",
      "metadata": {
        "id": "91f3dde3"
      },
      "source": [
        "## Import Python libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0515dec",
      "metadata": {
        "id": "a0515dec"
      },
      "outputs": [],
      "source": [
        "#data handling\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#data visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "#preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "#classification\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b45976a3",
      "metadata": {
        "id": "b45976a3"
      },
      "source": [
        "## Read data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25a5cb29",
      "metadata": {
        "id": "25a5cb29"
      },
      "outputs": [],
      "source": [
        "\n",
        "#read data directly from a github repository\n",
        "file_url='https://github.com/vappiah/Machine-Learning-Tutorials/raw/main/data/cancer_gene_expression.zip'\n",
        "\n",
        "dataframe=pd.read_csv(file_url)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e214ad93",
      "metadata": {
        "id": "e214ad93"
      },
      "source": [
        "\n",
        "## Data Exploration & Cleaning\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18e48d71",
      "metadata": {
        "scrolled": true,
        "id": "18e48d71"
      },
      "outputs": [],
      "source": [
        "#let's check the number of samples and features\n",
        "#note:the last column contain the labels. it is not considered as a feature\n",
        "\n",
        "print(dataframe.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7e833043",
      "metadata": {
        "id": "7e833043"
      },
      "outputs": [],
      "source": [
        "#let's check some of the columns (first, second and third columns)\n",
        "print(dataframe.columns[0:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2aee3bf1",
      "metadata": {
        "id": "2aee3bf1"
      },
      "outputs": [],
      "source": [
        "#lets check the name of the last column of this dataframe\n",
        "\n",
        "dataframe.columns[-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "229679e0",
      "metadata": {
        "id": "229679e0"
      },
      "outputs": [],
      "source": [
        "#check for missing values\n",
        "datanul=dataframe.isnull().sum()\n",
        "g=[i for i in datanul if i>0]\n",
        "\n",
        "print('columns with missing values:%d'%len(g))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "000af60f",
      "metadata": {
        "id": "000af60f"
      },
      "source": [
        "**GOOD JOB!!!!.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0560c5a",
      "metadata": {
        "scrolled": true,
        "id": "d0560c5a"
      },
      "outputs": [],
      "source": [
        "#let's check how many different cancer types are there in the data\n",
        "#note: in this tutorial the cancer types will be referred to as classes or labels\n",
        "\n",
        "print(dataframe['Cancer_Type'].value_counts())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "046d64c6",
      "metadata": {
        "id": "046d64c6"
      },
      "source": [
        "We can see that there are 5 classes/cancer types. And you can also see the number of samples diagnosed with a cancer type\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a0e165b",
      "metadata": {
        "id": "7a0e165b"
      },
      "source": [
        "\n",
        "## **Data preprocesing**\n",
        "This is done to put the data in an appropriate format before modelling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a13b9f51",
      "metadata": {
        "id": "a13b9f51"
      },
      "outputs": [],
      "source": [
        "#we will now seperate the feature values from the class. we do this because scikit-learn requires that features and class are separated before parsing them to the classifiers.\n",
        "X=dataframe.iloc[:,0:-1]\n",
        "y=dataframe.iloc[:,-1]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "264a01cb",
      "metadata": {
        "id": "264a01cb"
      },
      "source": [
        "\\\n",
        "**Encode labels**\n",
        "\n",
        "The labels for this data are categorical and we therefore have to convert them to numeric forms. This is referred to as encoding. Machine learning models usually require input data to be in numeric forms, hence we encoding the labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b251f08b",
      "metadata": {
        "id": "b251f08b"
      },
      "outputs": [],
      "source": [
        "#let's encode target labels (y) with values between 0 and n_classes-1.\n",
        "#encoding will be done using the LabelEncoder\n",
        "label_encoder=LabelEncoder()\n",
        "label_encoder.fit(y)\n",
        "y=label_encoder.transform(y)\n",
        "labels=label_encoder.classes_\n",
        "classes=np.unique(y)\n",
        "nclasses=np.unique(y).shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f68c4f6",
      "metadata": {
        "id": "5f68c4f6"
      },
      "source": [
        "\\\n",
        "**Data Splitting**\\\n",
        "Data is split into three: training, validation and test sets\\\n",
        "-training set is used for training\\\n",
        "-validation set is used for evaluating the model during training.\\\n",
        "-test set is used to test the model after training and tuning has been completed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7bcc2bde",
      "metadata": {
        "id": "7bcc2bde"
      },
      "outputs": [],
      "source": [
        "#split data into training,validation and test sets\n",
        "\n",
        "#split the data into training and test sets\n",
        "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)\n",
        "\n",
        "#split the training set into two (training and validation)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train,y_train,test_size=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0d1c8d5e",
      "metadata": {
        "id": "0d1c8d5e"
      },
      "source": [
        "\\\n",
        "**Data Normalization**\\\n",
        "Data normalization is done so that the values are in the same range. This will improve model performance and avoid bias.\\\n",
        "Normalization is performed separately on each data set. This is done to prevent data leakage."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7fc9256",
      "metadata": {
        "id": "b7fc9256"
      },
      "outputs": [],
      "source": [
        "### scale the data between 0-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a06d2f6",
      "metadata": {
        "id": "4a06d2f6"
      },
      "outputs": [],
      "source": [
        "min_max_scaler=MinMaxScaler()\n",
        "X_train=min_max_scaler.fit_transform(X_train)\n",
        "X_val=min_max_scaler.fit_transform(X_val)\n",
        "X_test=min_max_scaler.fit_transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7a1736a7",
      "metadata": {
        "id": "7a1736a7"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0f0ba2c",
      "metadata": {
        "id": "c0f0ba2c"
      },
      "source": [
        "### Build the Neural Network Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0f5060f",
      "metadata": {
        "scrolled": false,
        "id": "f0f5060f"
      },
      "outputs": [],
      "source": [
        "#define model\n",
        "model = Sequential()\n",
        "\n",
        "#hidden layer 1\n",
        "model.add(Dense(40, input_dim=X_train.shape[1], activation='relu'))\n",
        "\n",
        "#hidden layer 2\n",
        "model.add(Dense(20, activation='relu'))\n",
        "\n",
        "#output layer\n",
        "model.add(Dense(nclasses, activation='softmax'))\n",
        "\n",
        "#define optimizer and learning rate. We will use Adam optimizer\n",
        "opt_adam = keras.optimizers.Adam(learning_rate=0.001)\n",
        "\n",
        "model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(), optimizer=opt_adam, metrics=[keras.metrics.SparseCategoricalAccuracy()])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "080eb398",
      "metadata": {
        "scrolled": true,
        "id": "080eb398"
      },
      "outputs": [],
      "source": [
        "#fit the model to the training data\n",
        "history = model.fit(X_train, y_train, validation_data=(X_val, y_val), batch_size=32,epochs=200, verbose=1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f5a5b8bc",
      "metadata": {
        "scrolled": false,
        "id": "f5a5b8bc"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(X_test)\n",
        "_, accuracy = model.evaluate(X_test, y_test, verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e35f6f4a",
      "metadata": {
        "scrolled": true,
        "id": "e35f6f4a"
      },
      "outputs": [],
      "source": [
        "#get the predictions for the first 20 samples in the test set\n",
        "for index,entry in enumerate(predictions[0:20,:]):\n",
        "    print('predicted:%d ,actual:%d'%(np.argmax(entry),y_test[index]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b3ed706e",
      "metadata": {
        "id": "b3ed706e"
      },
      "outputs": [],
      "source": [
        "# summarize history for accuracy\n",
        "plt.plot(history.history['sparse_categorical_accuracy'])\n",
        "plt.plot(history.history['val_sparse_categorical_accuracy'])\n",
        "plt.title('model performance')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='lower right')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0ddadca",
      "metadata": {
        "id": "e0ddadca"
      },
      "outputs": [],
      "source": [
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='lower right')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "Neural Networks for Cancer Prediction -Episode-1.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
